{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T09:46:49.891925Z",
     "start_time": "2025-03-03T09:46:46.391132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from email.headerregistry import Address\n",
    "\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from sklearn.cluster import DBSCAN\n",
    "from glob import glob\n",
    "from PIL import Image"
   ],
   "id": "a244a6e5989d06b3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T09:55:48.598866Z",
     "start_time": "2025-03-03T09:55:48.536727Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 照片分类完成！\n"
     ]
    }
   ],
   "execution_count": 7,
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "PHOTO_DIR = \"photos/\"\n",
    "SORTED_DIR = \"sorted_photos/\"\n",
    "os.makedirs(SORTED_DIR, exist_ok=True)\n",
    "\n",
    "face_encodings = []\n",
    "face_image_paths = []\n",
    "\n",
    "for photo_path in glob(os.path.join(PHOTO_DIR, \"*.jpg\")):\n",
    "    try:\n",
    "        # 先用 PIL 打开图片并转换格式\n",
    "        with Image.open(photo_path) as img:\n",
    "            img = img.convert(\"RGB\")  # 确保是 RGB 格式\n",
    "            \n",
    "            img.save(photo_path)  # 保存转换后的图片\n",
    "\n",
    "        # 再用 face_recognition 读取\n",
    "        image = face_recognition.load_image_file(photo_path)\n",
    "        encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "        for encoding in encodings:\n",
    "            face_encodings.append(encoding)\n",
    "            face_image_paths.append(photo_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 处理 {photo_path} 时出错: {e}\")\n",
    "\n",
    "print(\"🎉 图片预处理完成，准备进行人脸分类！\")\n",
    "# 转换为 NumPy 数组\n",
    "face_encodings = np.array(face_encodings)\n",
    "\n",
    "# **1. DBSCAN 聚类**\n",
    "if len(face_encodings) > 0:\n",
    "    clustering = DBSCAN(eps=0.4, min_samples=1, metric=\"euclidean\").fit(face_encodings)\n",
    "    labels = clustering.labels_  # DBSCAN 输出的标签\n",
    "else:\n",
    "    labels = []\n",
    "# **2. 归类照片**\n",
    "for idx, label in enumerate(labels):\n",
    "    if label == -1:\n",
    "        person_folder = os.path.join(SORTED_DIR, \"Unknown\")  # 未分类人脸\n",
    "    else:\n",
    "        person_folder = os.path.join(SORTED_DIR, f\"人物{label+1}\")  # `label+1` 避免从0开始\n",
    "    \n",
    "    os.makedirs(person_folder, exist_ok=True)\n",
    "    shutil.copy(face_image_paths[idx], person_folder)\n",
    "\n",
    "print(\"🎉 照片分类完成！\")\n"
   ],
   "id": "88805d4077015d88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T08:44:47.169272Z",
     "start_time": "2025-03-03T08:44:47.153251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_by_people(photo_path, known_faces, known_names):\n",
    "    \"\"\"\n",
    "    识别人脸并分类到相应文件夹\n",
    "    \"\"\"\n",
    "    image = face_recognition.load_image_file(photo_path)\n",
    "    face_encodings = face_recognition.face_encodings(image)\n",
    "\n",
    "    for encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_faces, encoding)\n",
    "        if True in matches:\n",
    "            matched_index = matches.index(True)\n",
    "            person_name = known_names[matched_index]\n",
    "        else:\n",
    "            person_name = \"Unknown\"\n",
    "\n",
    "        person_folder = os.path.join(SORTED_DIR, \"People\", person_name)\n",
    "        os.makedirs(person_folder, exist_ok=True)\n",
    "        shutil.copy(photo_path, person_folder)"
   ],
   "id": "875d4b8c4fc94e4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photos/1.jpg -> Mode: RGB, Format: JPEG\n",
      "photos/2.jpg -> Mode: RGB, Format: JPEG\n",
      "photos/3.jpg -> Mode: RGB, Format: JPEG\n",
      "photos/4.jpg -> Mode: RGB, Format: JPEG\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:58:50.989162Z",
     "start_time": "2025-03-18T15:58:50.977525Z"
    }
   },
   "cell_type": "code",
   "source": "next_label_id = 1",
   "id": "bebd431dfc72d609",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8408d9dc302422da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T06:23:04.125134Z",
     "start_time": "2025-04-07T06:23:04.107626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "PHOTO_DIR = \"photos/\"\n",
    "SORTED_DIR = \"sorted_photos/\"\n",
    "ENCODINGS_FILE = \"face_encodings.json\"\n",
    "\n",
    "os.makedirs(SORTED_DIR, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# 🌟 加载已有的人脸数据（JSON 文件）\n",
    "# ==========================\n",
    "def load_encodings():\n",
    "    global next_label_id\n",
    "    if not os.path.exists(ENCODINGS_FILE):\n",
    "        print(\"📂 没有检测到现有的人脸数据库，初始化为空。\")\n",
    "        return {}, [], []\n",
    "\n",
    "    with open(ENCODINGS_FILE, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    known_face_dict = {}  # {label: encoding (np array)}\n",
    "    known_face_encodings = []\n",
    "    known_face_labels = []\n",
    "\n",
    "    for label, encoding_list in data.items():\n",
    "        label_int = int(label)\n",
    "        encoding_array = np.array(encoding_list)\n",
    "        known_face_dict[label_int] = encoding_array\n",
    "        known_face_encodings.append(encoding_array)\n",
    "        known_face_labels.append(label_int)\n",
    "    \n",
    "    next_label_id = max(known_face_dict.keys(), default=0) + 1\n",
    "    print(f\"✅ 成功加载 {len(known_face_dict)} 个已知人物数据。\")\n",
    "    return known_face_dict, known_face_encodings, known_face_labels\n",
    "\n",
    "# ==========================\n",
    "# 🌟 保存人脸编码到 JSON\n",
    "# ==========================\n",
    "def save_encodings(known_face_dict):\n",
    "    data_to_save = {}\n",
    "    for label, encoding_array in known_face_dict.items():\n",
    "        data_to_save[label] = encoding_array.tolist()  # 转成 JSON 可保存的 list\n",
    "    \n",
    "    with open(ENCODINGS_FILE, 'w') as f:\n",
    "        json.dump(data_to_save, f)\n",
    "    \n",
    "    print(f\"💾 已保存 {len(data_to_save)} 个人物的编码数据到 {ENCODINGS_FILE}\")\n",
    "\n",
    "# ==========================\n",
    "# 🌟 初始化已知人脸数据\n",
    "# ==========================\n",
    "known_face_dict, known_face_encodings, known_face_labels = load_encodings()\n",
    "\n",
    "# ==========================\n",
    "# 🌟 处理单张图片\n",
    "# ==========================\n",
    "def process_new_photo(photo_path):\n",
    "    global next_label_id\n",
    "    try:\n",
    "        # 1. 打开并转换图片\n",
    "        with Image.open(photo_path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "            image_array = np.array(img)\n",
    "        \n",
    "        # 2. 人脸识别\n",
    "        encodings = face_recognition.face_encodings(image_array)\n",
    "\n",
    "        if not encodings:\n",
    "            print(f\"⚠️ 图片 {photo_path} 不包含人脸，跳过处理。\")\n",
    "            return\n",
    "        \n",
    "        print(f\"✅ 识别到 {len(encodings)} 张人脸，开始分类...\")\n",
    "\n",
    "        for encoding in encodings:\n",
    "            if len(known_face_encodings) == 0:\n",
    "                # 没有人脸数据，直接新建人物\n",
    "                person_label = next_label_id\n",
    "                next_label_id += 1\n",
    "\n",
    "                known_face_dict[person_label] = encoding\n",
    "                known_face_encodings.append(encoding)\n",
    "                known_face_labels.append(person_label)\n",
    "                print(f\"🆕 未检测到已有人物，新建人物 {person_label}\")\n",
    "\n",
    "            else:\n",
    "                # 比较与已知人脸的相似度\n",
    "                distances = face_recognition.face_distance(known_face_encodings, encoding)\n",
    "                min_distance = np.min(distances)\n",
    "                best_match_index = np.argmin(distances)\n",
    "\n",
    "                if min_distance < 0.4:  # 阈值可以调整\n",
    "                    person_label = known_face_labels[best_match_index]\n",
    "                    # print(f\"👌 匹配到人物 {person_label}，距离为 {min_distance:.2f}\")\n",
    "                else:\n",
    "                    # 新人物\n",
    "                    person_label = next_label_id\n",
    "                    next_label_id += 1\n",
    "\n",
    "                    known_face_dict[person_label] = encoding\n",
    "                    known_face_encodings.append(encoding)\n",
    "                    known_face_labels.append(person_label)\n",
    "                    # print(f\"🆕 新建人物 {person_label}，距离为 {min_distance:.2f}\")\n",
    "            \n",
    "            # 保存照片到分类目录\n",
    "            person_folder = os.path.join(SORTED_DIR, f\"人物{person_label}\")\n",
    "            os.makedirs(person_folder, exist_ok=True)\n",
    "            shutil.copy(photo_path, person_folder)\n",
    "        \n",
    "        # 处理完图片，保存最新的 encodings\n",
    "        save_encodings(known_face_dict)\n",
    "        return person_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 处理 {photo_path} 时出错: {e}\")\n",
    "\n",
    "# ===============================\n",
    "# 🌟 遍历已有的 PHOTO_DIR 图片，模拟上传流程\n",
    "# ===============================\n",
    "# all_photos = glob(os.path.join(PHOTO_DIR, \"*.jpg\"))\n",
    "# \n",
    "# print(f\"\\n🚀 开始处理图片，检测照片数量: {len(all_photos)} 张\\n\")\n",
    "# \n",
    "# for photo in all_photos:\n",
    "#     process_new_photo(photo)\n",
    "# \n",
    "# print(\"\\n🎉 所有图片处理完成！\")\n"
   ],
   "id": "a53195f446091917",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功加载 10 个已知人物数据。\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T08:46:30.702093Z",
     "start_time": "2025-03-19T08:46:30.530130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import piexif\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_decimal_from_dms(dms, ref):\n",
    "    \"\"\"Convert GPS coordinates in DMS to decimal format.\"\"\"\n",
    "    degrees = dms[0][0] / dms[0][1]\n",
    "    minutes = dms[1][0] / dms[1][1]\n",
    "    seconds = dms[2][0] / dms[2][1]\n",
    "\n",
    "    decimal = degrees + (minutes / 60.0) + (seconds / 3600.0)\n",
    "\n",
    "    if ref in ['S', 'W']:\n",
    "        decimal = -decimal\n",
    "    return decimal\n",
    "\n",
    "def reverse_geocode(lat, lon):\n",
    "    \"\"\"Use geopy to reverse geocode latitude and longitude to address.\"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"photo_metadata_app\")\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), exactly_one=True, language='en')\n",
    "        if location:\n",
    "            return location.address\n",
    "        else:\n",
    "            return \"Address not found\"\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving address: {e}\"\n",
    "\n",
    "def extract_exif_data(image_path):\n",
    "    # 打开图片文件\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # 获取 EXIF 信息\n",
    "    exif_data = img._getexif()\n",
    "\n",
    "    # 提取拍摄时间\n",
    "    timestamp = None\n",
    "    if exif_data and 36867 in exif_data:\n",
    "        timestamp = exif_data[36867]  # DateTimeOriginal\n",
    "        timestamp = datetime.strptime(timestamp, '%Y:%m:%d %H:%M:%S')\n",
    "\n",
    "    # 使用 piexif 加载更详细的 EXIF 数据\n",
    "    exif_dict = piexif.load(img.info['exif']) if 'exif' in img.info else None\n",
    "\n",
    "    # 提取相机/设备信息\n",
    "    camera_model = None\n",
    "    if exif_dict:\n",
    "        model = exif_dict['0th'].get(piexif.ImageIFD.Model, None)\n",
    "        make = exif_dict['0th'].get(piexif.ImageIFD.Make, None)\n",
    "\n",
    "        camera_model = \"\"\n",
    "        if make:\n",
    "            camera_model += make.decode('utf-8') + \" \"\n",
    "        if model:\n",
    "            camera_model += model.decode('utf-8')\n",
    "\n",
    "    # 提取 GPS 信息\n",
    "    gps_info = exif_dict.get('GPS', None) if exif_dict else None\n",
    "    latitude = longitude = None\n",
    "    address = None\n",
    "    if gps_info:\n",
    "        gps_latitude = gps_info.get(piexif.GPSIFD.GPSLatitude)\n",
    "        gps_latitude_ref = gps_info.get(piexif.GPSIFD.GPSLatitudeRef).decode('utf-8')\n",
    "        gps_longitude = gps_info.get(piexif.GPSIFD.GPSLongitude)\n",
    "        gps_longitude_ref = gps_info.get(piexif.GPSIFD.GPSLongitudeRef).decode('utf-8')\n",
    "\n",
    "        if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n",
    "            latitude = get_decimal_from_dms(gps_latitude, gps_latitude_ref)\n",
    "            longitude = get_decimal_from_dms(gps_longitude, gps_longitude_ref)\n",
    "\n",
    "            # 反向地理编码获取地址\n",
    "            address = reverse_geocode(latitude, longitude)\n",
    "\n",
    "    # 返回提取的信息\n",
    "    return {\n",
    "        'Timestamp': timestamp,\n",
    "        'Latitude': latitude,\n",
    "        'Longitude': longitude,\n",
    "        'Address': address,\n",
    "        'Camera/Device': camera_model\n",
    "    }\n",
    "\n",
    "# 示例：测试一张图片\n",
    "image_file = 'photos/13.jpg'  # 替换为你自己的图片路径\n",
    "metadata = extract_exif_data(image_file)\n",
    "\n",
    "print(\"Metadata extracted from image:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n"
   ],
   "id": "119eb4b9ffdfbeeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata extracted from image:\n",
      "Timestamp: None\n",
      "Latitude: None\n",
      "Longitude: None\n",
      "Address: None\n",
      "Camera/Device: None\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T08:47:02.681362Z",
     "start_time": "2025-03-19T08:46:37.907080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "# 加载 BLIP 模型和处理器\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ],
   "id": "885f9c9dcc721413",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T08:47:21.614320Z",
     "start_time": "2025-03-19T08:47:18.798482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 生成图片描述\n",
    "def generate_caption(image_path):\n",
    "    try:\n",
    "        raw_image = Image.open(image_path).convert('RGB')\n",
    "        inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "        out = model.generate(**inputs)\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        print(f\"Caption generation error for {image_path}: {e}\")\n",
    "        return \"No description available.\"\n",
    "\n",
    "caption = generate_caption(\"photos/11.jpg\")\n",
    "print(f\"Image description: {caption}\")\n"
   ],
   "id": "6c4d88e2f3d90bc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image description: a plate of food with cuce and sauce on it\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T08:47:29.801324Z",
     "start_time": "2025-03-19T08:47:23.585565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "# 自动下载模型\n",
    "download(\"en_core_web_sm\")\n",
    "\n",
    "# 加载模型\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "id": "ee1f7c8b36fdcdf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001B[38;5;3m⚠ Restart to reload dependencies\u001B[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:46:45.122023Z",
     "start_time": "2025-04-13T16:46:45.112774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_noun_tags(text):\n",
    "    \"\"\"\n",
    "    提取英文文本中的关键词（名词和专有名词）\n",
    "\n",
    "    参数:\n",
    "        text (str): 输入的英文文本\n",
    "\n",
    "    返回:\n",
    "        tags (list): 去重且小写处理后的关键词列表\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    # 分词 & 词性标注\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # 只保留名词（NOUN）和专有名词（PROPN）\n",
    "    tags = [token.text for token in doc if token.pos_ in ['NOUN', 'PROPN']]\n",
    "\n",
    "    # 去重 & 小写（可根据需求取消小写处理）\n",
    "    tags = list(set(tag.lower() for tag in tags))\n",
    "    \n",
    "    print(f\"Image event tags: {tags}\")\n",
    "\n",
    "    return tags\n"
   ],
   "id": "f6d4fb14024ce09c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:47:50.329050Z",
     "start_time": "2025-04-13T16:47:50.316641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 处理文件夹下所有图片\n",
    "def process_images(img_path):\n",
    "    # 提取元信息\n",
    "    metadata = extract_exif_data(img_path)\n",
    "    \n",
    "    # 生成描述\n",
    "    caption = generate_caption(img_path)\n",
    "\n",
    "    #Aoto-tagging\n",
    "    tags = extract_noun_tags(caption)\n",
    "    \n",
    "    #人脸识别 \n",
    "    person_label = process_new_photo(img_path)\n",
    "    \n",
    "    # ✅ 平铺 JSON 格式\n",
    "    photo_info = {\n",
    "        'Timestamp': metadata.get('Timestamp'),\n",
    "        'Latitude': metadata.get('Latitude'),\n",
    "        'Longitude': metadata.get('Longitude'),\n",
    "        'Address': metadata.get('Address'),\n",
    "        'Camera/Device': metadata.get('Camera/Device'),\n",
    "        'Caption': caption,\n",
    "        'AutoTags': tags,\n",
    "        'PersonLabel': person_label\n",
    "    }\n",
    "    \n",
    "    print(f\"Processed {img_path}: {caption} @ {photo_info.get('Address')} on {photo_info.get('Timestamp')}\") \n",
    "    \n",
    "    return photo_info"
   ],
   "id": "46ce3a654dd8ea2f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:47:54.808561Z",
     "start_time": "2025-04-13T16:47:54.600142Z"
    }
   },
   "cell_type": "code",
   "source": "process_images(\"photos/6.jpg\")",
   "id": "1d3d495bb00ec32f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_exif_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mprocess_images\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mphotos/6.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[2], line 4\u001B[0m, in \u001B[0;36mprocess_images\u001B[1;34m(img_path)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mprocess_images\u001B[39m(img_path):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;66;03m# 提取元信息\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m     metadata \u001B[38;5;241m=\u001B[39m \u001B[43mextract_exif_data\u001B[49m(img_path)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# 生成描述\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     caption \u001B[38;5;241m=\u001B[39m generate_caption(img_path)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'extract_exif_data' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T09:20:57.399205Z",
     "start_time": "2025-03-19T09:20:57.141797Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "76c3a6abe1908bfc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.responses import JSONResponse\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# 上传图片接口\n",
    "@app.post(\"/process_image\")\n",
    "async def process_image(file: UploadFile = File(...)):\n",
    "    try:        \n",
    "        # 调用处理函数\n",
    "        result = process_images(file)\n",
    "\n",
    "        # 返回 JSON\n",
    "        return JSONResponse(content=result)\n",
    "\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n"
   ],
   "id": "f68c0dcacdcd6c53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T04:55:30.342397Z",
     "start_time": "2025-03-15T04:55:29.146545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "# 第一步：获取上传 URL\n",
    "url_get_upload_url = \"https://api.immersity.ai/api/v1/get-upload-url\"\n",
    "headers = {\"accept\": \"application/json\"}\n",
    "\n",
    "response = requests.get(url_get_upload_url, headers=headers)\n",
    "\n",
    "# 检查是否成功返回上传 URL\n",
    "if response.status_code == 200:\n",
    "    upload_url = response.json().get('upload_url')\n",
    "    if upload_url:\n",
    "        print(f\"上传 URL: {upload_url}\")\n",
    "        \n",
    "        # 第二步：上传图片到服务器\n",
    "        file_path = \"/mnt/data/image.png\"  # 你的图片文件路径\n",
    "\n",
    "        files = {\n",
    "            \"file\": open(file_path, \"rb\")\n",
    "        }\n",
    "\n",
    "        upload_response = requests.post(upload_url, files=files)\n",
    "        files['file'].close()\n",
    "\n",
    "        # 检查上传是否成功\n",
    "        if upload_response.status_code == 200:\n",
    "            print(\"图片上传成功。\")\n",
    "            uploaded_file_url = upload_response.json().get(\"file_url\")\n",
    "            print(f\"文件 URL: {uploaded_file_url}\")\n",
    "\n",
    "            # 第三步：创建 3D 动画\n",
    "            url_animation = \"https://api.immersity.ai/api/v1/animation\"\n",
    "            headers = {\n",
    "                \"accept\": \"application/json\",\n",
    "                \"content-type\": \"application/json\"\n",
    "            }\n",
    "\n",
    "            data = {\n",
    "                \"image_url\": uploaded_file_url  # 使用上传后的文件 URL\n",
    "            }\n",
    "\n",
    "            response_animation = requests.post(url_animation, json=data, headers=headers)\n",
    "\n",
    "            # 打印 API 返回的响应，确认 3D 动画生成成功\n",
    "            if response_animation.status_code == 200:\n",
    "                print(\"3D 动画生成成功。\")\n",
    "                print(\"响应: \", response_animation.json())\n",
    "            else:\n",
    "                print(\"生成动画失败。\")\n",
    "                print(\"错误: \", response_animation.text)\n",
    "        else:\n",
    "            print(\"图片上传失败。\")\n",
    "            print(f\"错误: {upload_response.text}\")\n",
    "    else:\n",
    "        print(\"错误：没有返回上传 URL。\")\n",
    "else:\n",
    "    print(f\"获取上传 URL 失败。错误: {response.text}\")\n"
   ],
   "id": "3c46353d8be02d52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取上传 URL 失败。错误: {\"message\":\"Unauthorized\",\"statusCode\":401}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://auth.immersity.ai/auth/realms/immersity/protocol/openid-connect/token\"\n",
    "\n",
    "# 替换为你自己的 client_id 和 client_secret\n",
    "client_id = \"a549150e-3f5f-472d-9cae-ace8f9748c99\"\n",
    "client_secret = \"gwAaBb5sTXZs4wqWnch3MOrgPU8LLmYe\"\n",
    "\n",
    "# 请求参数\n",
    "payload = {\n",
    "    \"grant_type\": \"client_credentials\",\n",
    "    \"client_id\": client_id,\n",
    "    \"client_secret\": client_secret\n",
    "}\n",
    "\n",
    "# 请求头\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/x-www-form-urlencoded\"\n",
    "}\n",
    "\n",
    "# 发起 POST 请求\n",
    "response = requests.post(url, data=payload, headers=headers)\n",
    "\n",
    "# 查看返回值\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ],
   "id": "a3ed82499bc9e79b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:17:30.367312Z",
     "start_time": "2025-03-21T15:17:23.225540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Step 1: 获取 Access Token\n",
    "url_auth = \"https://auth.immersity.ai/auth/realms/immersity/protocol/openid-connect/token\"\n",
    "\n",
    "client_id = \"a549150e-3f5f-472d-9cae-ace8f9748c99\"\n",
    "client_secret = \"gwAaBb5sTXZs4wqWnch3MOrgPU8LLmYe\"\n",
    "\n",
    "payload = {\n",
    "    \"grant_type\": \"client_credentials\",\n",
    "    \"client_id\": client_id,\n",
    "    \"client_secret\": client_secret\n",
    "}\n",
    "\n",
    "headers_auth = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/x-www-form-urlencoded\"\n",
    "}\n",
    "\n",
    "response_auth = requests.post(url_auth, data=payload, headers=headers_auth)\n",
    "\n",
    "if response_auth.status_code == 200:\n",
    "    access_token = response_auth.json().get(\"access_token\")\n",
    "    print(f\"✅ Access Token 获取成功: {access_token}\\n\")\n",
    "else:\n",
    "    print(\"❌ 获取 Access Token 失败。\")\n",
    "    print(f\"错误信息: {response_auth.text}\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: 获取上传 URL\n",
    "url_get_upload_url = \"https://api.immersity.ai/api/v1/get-upload-url\"\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {access_token}\"\n",
    "}\n",
    "\n",
    "response = requests.get(url_get_upload_url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    upload_url = response.json().get('url')\n",
    "    if upload_url:\n",
    "        print(f\"✅ 获取上传 URL 成功: {upload_url}\\n\")\n",
    "\n",
    "        # Step 3: 上传图片到服务器\n",
    "        file_path = \"photos/10.jpg\"\n",
    "\n",
    "        if not os.path.isfile(file_path):\n",
    "            print(f\"❌ 文件未找到: {file_path}\")\n",
    "            exit()\n",
    "\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            upload_response = requests.put(upload_url, data=f)\n",
    "\n",
    "        if upload_response.status_code in [200, 201]:\n",
    "            print(\"✅ 图片上传成功！\\n\")\n",
    "\n",
    "            # Step 4: 创建 3D 动画\n",
    "            url_animation = \"https://api.immersity.ai/api/v1/animation\"\n",
    "            headers_animation = {\n",
    "                \"accept\": \"application/json\",\n",
    "                \"content-type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {access_token}\"\n",
    "            }\n",
    "\n",
    "            # uploaded_file_url 这里根据 API 文档确认，如果 upload_url 可以用来创建动画，就直接用。\n",
    "            # 否则你需要 API 提供 file_url，如果没有返回，就可能需要你自己拼接 URL。\n",
    "            data = {\n",
    "                \"image_url\": upload_url.split(\"?\")[0]  # 通常上传 URL 去掉参数部分就是文件 URL\n",
    "            }\n",
    "\n",
    "            print(f\"➡️  发送创建动画请求，使用图片 URL: {data['image_url']}\\n\")\n",
    "\n",
    "            response_animation = requests.post(url_animation, json=data, headers=headers_animation)\n",
    "\n",
    "            if response_animation.status_code == 200:\n",
    "                print(\"✅ 3D 动画生成成功！\")\n",
    "                print(\"响应内容: \", response_animation.json())\n",
    "            else:\n",
    "                print(\"❌ 生成动画失败。\")\n",
    "                print(f\"错误信息: {response_animation.text}\")\n",
    "        else:\n",
    "            print(\"❌ 图片上传失败。\")\n",
    "            print(f\"错误信息: {upload_response.text}\")\n",
    "    else:\n",
    "        print(\"❌ 获取上传 URL 成功，但未返回 URL。\")\n",
    "else:\n",
    "    print(f\"❌ 获取上传 URL 失败。错误信息: {response.text}\")\n",
    "\n"
   ],
   "id": "d94c987e9db9e6d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Access Token 获取成功: eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICJVbDlpOTVQaVdhVXlsYmdQQVdZcERyS0NibWZhbUt3NnJWMk5jdWlwX09FIn0.eyJleHAiOjE3NDI1NzEyMzUsImlhdCI6MTc0MjU3MDMzNSwianRpIjoiZDViYzA3MTUtNDlhNi00ZjJjLTliODgtN2U5NDYxMTJjNWM5IiwiaXNzIjoiaHR0cHM6Ly9hdXRoLmltbWVyc2l0eS5haS9hdXRoL3JlYWxtcy9pbW1lcnNpdHkiLCJzdWIiOiJiOGFhNTliNC01OThjLTQ1NjYtYWVkNS1iYzA4MzdkMzA2MDAiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJhNTQ5MTUwZS0zZjVmLTQ3MmQtOWNhZS1hY2U4Zjk3NDhjOTkiLCJzY29wZSI6ImxlaWEtYXBpLWdhdGV3YXkiLCJjbGllbnRIb3N0IjoiODIuMTUzLjEzNS4yMTMiLCJjbGllbnQtb3duZXItdXNlci1pZCI6ImEyYTVlMDNlLTJjZmEtNGU1NS1hMmNiLTQyZGY1OWE1YTM2ZiIsImNsaWVudElkIjoiYTU0OTE1MGUtM2Y1Zi00NzJkLTljYWUtYWNlOGY5NzQ4Yzk5IiwiY2xpZW50QWRkcmVzcyI6IjgyLjE1My4xMzUuMjEzIn0.GPupfrQ1WqYuq9BEh_uU3ybRJgme-l4AlEISIPE0O6J7MWHMiID7NwR-AndvgUW1Hq4VNZGIOFpQsAz9eqMzUgEHPFL1UVvYSPuH_ndf4UMp40q_jSaW84KDQuNv0n0p0HnvU1S6KYop2DdjuvP1zycazQ3gJMf98XdjO79IIyQq7fTKUC1N7WM5GPvkYysDEf6F1AH4e-eOu4vRUjECR0VC0EsU3ZJxUM-a0nyc2ojVeY3vl8liCR0O3FuxyCPvRSb2Sw-V3uYRn-lgZ1HrQyl6OfWkj_pXf-4uHHct9sMqiq-kHFK6NqFiQN237NAW7hzkDdhGhdZfhKap3s0tJg\n",
      "\n",
      "✅ 获取上传 URL 成功: https://leia-storage-service-production.s3.us-east-1.amazonaws.com/timed/D001/a2a5e03e-2cfa-4e55-a2cb-42df59a5a36f/e5e3d5a3-a35d-4c2f-9f9e-5324f5f402ec/f8de160c-3266-4279-a921-0bb70f32c9b2?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIASC7ECGJVHARKLZ6E%2F20250321%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250321T151857Z&X-Amz-Expires=86400&X-Amz-Signature=4781664f29705f426abfd9e207b0a76e1e8856be778c985dbbce34491b915d89&X-Amz-SignedHeaders=host&x-id=PutObject\n",
      "\n",
      "✅ 图片上传成功！\n",
      "\n",
      "➡️  发送创建动画请求，使用图片 URL: https://leia-storage-service-production.s3.us-east-1.amazonaws.com/timed/D001/a2a5e03e-2cfa-4e55-a2cb-42df59a5a36f/e5e3d5a3-a35d-4c2f-9f9e-5324f5f402ec/f8de160c-3266-4279-a921-0bb70f32c9b2\n",
      "\n",
      "❌ 生成动画失败。\n",
      "错误信息: {\"statusCode\":400,\"message\":\"Validation failed\",\"details\":{\"errors\":[{\"parameterName\":\"inputImageUrl\",\"messages\":[\"inputImageUrl must be a URL address\"]}]}}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T05:26:21.113610Z",
     "start_time": "2025-03-15T05:26:21.045591Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b202e468781bb639",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m upload_response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mupload_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\api.py:130\u001B[0m, in \u001B[0;36mput\u001B[1;34m(url, data, **kwargs)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mput\u001B[39m(url, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    119\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a PUT request.\u001B[39;00m\n\u001B[0;32m    120\u001B[0m \n\u001B[0;32m    121\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m request(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mput\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, data\u001B[38;5;241m=\u001B[39mdata, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[1;34m(method, url, **kwargs)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m session\u001B[38;5;241m.\u001B[39mrequest(method\u001B[38;5;241m=\u001B[39mmethod, url\u001B[38;5;241m=\u001B[39murl, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\sessions.py:575\u001B[0m, in \u001B[0;36mSession.request\u001B[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[0;32m    562\u001B[0m \u001B[38;5;66;03m# Create the Request.\u001B[39;00m\n\u001B[0;32m    563\u001B[0m req \u001B[38;5;241m=\u001B[39m Request(\n\u001B[0;32m    564\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod\u001B[38;5;241m.\u001B[39mupper(),\n\u001B[0;32m    565\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    573\u001B[0m     hooks\u001B[38;5;241m=\u001B[39mhooks,\n\u001B[0;32m    574\u001B[0m )\n\u001B[1;32m--> 575\u001B[0m prep \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    577\u001B[0m proxies \u001B[38;5;241m=\u001B[39m proxies \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[0;32m    579\u001B[0m settings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmerge_environment_settings(\n\u001B[0;32m    580\u001B[0m     prep\u001B[38;5;241m.\u001B[39murl, proxies, stream, verify, cert\n\u001B[0;32m    581\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\sessions.py:484\u001B[0m, in \u001B[0;36mSession.prepare_request\u001B[1;34m(self, request)\u001B[0m\n\u001B[0;32m    481\u001B[0m     auth \u001B[38;5;241m=\u001B[39m get_netrc_auth(request\u001B[38;5;241m.\u001B[39murl)\n\u001B[0;32m    483\u001B[0m p \u001B[38;5;241m=\u001B[39m PreparedRequest()\n\u001B[1;32m--> 484\u001B[0m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupper\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdict_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCaseInsensitiveDict\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_setting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauth\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcookies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerged_cookies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhooks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmerge_hooks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhooks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhooks\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\models.py:370\u001B[0m, in \u001B[0;36mPreparedRequest.prepare\u001B[1;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_headers(headers)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_cookies(cookies)\n\u001B[1;32m--> 370\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare_body\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    371\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_auth(auth, url)\n\u001B[0;32m    373\u001B[0m \u001B[38;5;66;03m# Note that prepare_auth must be last to enable authentication schemes\u001B[39;00m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;66;03m# such as OAuth to work on a fully prepared request.\u001B[39;00m\n\u001B[0;32m    375\u001B[0m \n\u001B[0;32m    376\u001B[0m \u001B[38;5;66;03m# This MUST go after prepare_auth. Authenticators could add a hook\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\models.py:558\u001B[0m, in \u001B[0;36mPreparedRequest.prepare_body\u001B[1;34m(self, data, files, json)\u001B[0m\n\u001B[0;32m    556\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    557\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m--> 558\u001B[0m         body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_encode_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    559\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, basestring) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(data, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    560\u001B[0m             content_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\models.py:124\u001B[0m, in \u001B[0;36mRequestEncodingMixin._encode_params\u001B[1;34m(data)\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(vs, basestring) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(vs, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__iter__\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    123\u001B[0m     vs \u001B[38;5;241m=\u001B[39m [vs]\n\u001B[1;32m--> 124\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m vs:\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    126\u001B[0m         result\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m    127\u001B[0m             (\n\u001B[0;32m    128\u001B[0m                 k\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(k, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m k,\n\u001B[0;32m    129\u001B[0m                 v\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m v,\n\u001B[0;32m    130\u001B[0m             )\n\u001B[0;32m    131\u001B[0m         )\n",
      "\u001B[1;31mValueError\u001B[0m: I/O operation on closed file."
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T15:16:49.428409Z",
     "start_time": "2025-03-21T15:16:49.182220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import sys\n",
    "# import os\n",
    "# import uuid\n",
    "# import requests\n",
    "# from get_access_token import *\n",
    "#\n",
    "# MEDIA_CLOUD_REST_API_BASE_URL = 'https://api.immersity.ai'\n",
    "#\n",
    "# DEFAULT_ORIGINAL_IMAGE_URL = 'https://images.pexels.com/photos/38771/pexels-photo-38771.jpeg?auto=compress&cs' \\\n",
    "#                              '=tinysrgb&w=1260&h=750&dpr=1'\n",
    "# ORIGINAL_IMAGE_URL = os.getenv('ORIGINAL_IMAGE_URL', DEFAULT_ORIGINAL_IMAGE_URL)\n",
    "# ORIGINAL_IMAGE_URL = DEFAULT_ORIGINAL_IMAGE_URL if ORIGINAL_IMAGE_URL == '' else ORIGINAL_IMAGE_URL\n",
    "#\n",
    "# THREE_MIN_IN_S = 3 * 60\n",
    "#\n",
    "#\n",
    "# try:\n",
    "#     print('Acquiring access token from Immersity AI Login...')\n",
    "#     access_token = get_access_token()\n",
    "#     print(f'\\nImmersity AI Login AccessToken acquired: {access_token}')\n",
    "#\n",
    "#     correlation_id = str(uuid.uuid4())\n",
    "#     print(f'\\nGenerating Disparity with correlationId: {correlation_id}...')\n",
    "#\n",
    "#     response = requests.post(\n",
    "#         f'{MEDIA_CLOUD_REST_API_BASE_URL}/api/v1/animation',\n",
    "#         headers={\n",
    "#             'Authorization': f'Bearer {access_token}'\n",
    "#         },\n",
    "#         json={\n",
    "#             'correlationId': correlation_id,\n",
    "#             'inputImageUrl': ORIGINAL_IMAGE_URL,\n",
    "#             'inputDisparityUrl': disparity_url,\n",
    "#             'animationLength': 5\n",
    "#         },\n",
    "#         timeout=THREE_MIN_IN_S\n",
    "#     )\n",
    "#     if not response.status_code == 201:\n",
    "#         raise Exception(f\"Request returned with an error {response.status_code}. \"\n",
    "#                         f\"The full response is: {response.content}\")\n",
    "#\n",
    "#     # The resulting file is accessible via the pre-signed GET URL, that you\n",
    "#     # can find included in the response to the animation request:\n",
    "#     get_mp4_presigned_url = response.json()['resultPresignedUrl']\n",
    "#     print(f'\\nMP4 Animation has been uploaded to the temporary storage. '\n",
    "#           f'To download, please use this GET URL: {get_mp4_presigned_url}')\n",
    "#\n",
    "# \t\t# We omit the error handling in this example for simplicity, but\n",
    "#     # you should always check for a returned status & errors from the API\n",
    "#     # in real code.\n",
    "#\n",
    "# except Exception as e:\n",
    "#     print('Error. Unhandled exception: ' + str(e), file=sys.stderr)\n"
   ],
   "id": "176ef28d000f105e",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'get_access_token'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01muuid\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mget_access_token\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      7\u001B[0m MEDIA_CLOUD_REST_API_BASE_URL \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://api.immersity.ai\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      9\u001B[0m DEFAULT_ORIGINAL_IMAGE_URL \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://images.pexels.com/photos/38771/pexels-photo-38771.jpeg?auto=compress&cs\u001B[39m\u001B[38;5;124m'\u001B[39m \\\n\u001B[0;32m     10\u001B[0m                              \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m=tinysrgb&w=1260&h=750&dpr=1\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'get_access_token'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T02:55:50.066560Z",
     "start_time": "2025-03-26T02:55:50.030769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from moviepy.editor import *\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def create_video(image_folder, audio_path, output_path, fps=24, duration_per_image=3, transition_duration=1):\n",
    "    # 获取所有图片并按文件名排序\n",
    "    image_files = sorted(glob.glob(os.path.join(image_folder, \"*.*\")))\n",
    "    \n",
    "    # 创建图片剪辑列表（统一调整为1920x1080分辨率）\n",
    "    clips = []\n",
    "    for img in image_files:\n",
    "        clip = ImageClip(img).set_duration(duration_per_image).resize((1920, 1080))\n",
    "        clip = clip.crossfadein(transition_duration).crossfadeout(transition_duration)\n",
    "        clips.append(clip)\n",
    "\n",
    "    # 拼接视频剪辑（使用过渡重叠）\n",
    "    final_clip = concatenate_videoclips(\n",
    "        clips,\n",
    "        method=\"compose\",\n",
    "        padding=-transition_duration  # 负值表示重叠时间\n",
    "    )\n",
    "\n",
    "    # 添加背景音乐\n",
    "    audio_clip = AudioFileClip(audio_path)\n",
    "    if audio_clip.duration < final_clip.duration:\n",
    "        # 循环音频\n",
    "        audio_clip = audio_clip.fx(vfx.loop, duration=final_clip.duration)\n",
    "    else:\n",
    "        # 截取音频\n",
    "        audio_clip = audio_clip.subclip(0, final_clip.duration)\n",
    "    \n",
    "    final_clip = final_clip.set_audio(audio_clip)\n",
    "\n",
    "    # 输出视频\n",
    "    final_clip.write_videofile(\n",
    "        output_path,\n",
    "        fps=fps,\n",
    "        codec=\"libx264\",\n",
    "        audio_codec=\"aac\",\n",
    "        threads=8,\n",
    "        preset=\"medium\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 参数配置\n",
    "    config = {\n",
    "        \"image_folder\": \"/path/to/your/images\",  # 图片文件夹路径\n",
    "        \"audio_path\": \"/path/to/background_music.mp3\",  # 背景音乐路径\n",
    "        \"output_path\": \"output_video.mp4\",        # 输出视频路径\n",
    "        \"fps\": 30,                                # 帧率\n",
    "        \"duration_per_image\": 3,                  # 每张图片显示时间（秒）\n",
    "        \"transition_duration\": 1                  # 过渡特效时间（秒）\n",
    "    }\n",
    "    \n",
    "    create_video(**config)"
   ],
   "id": "33d15aa19db9e926",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mmoviepy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meditor\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mglob\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T03:18:25.460654Z",
     "start_time": "2025-03-26T03:18:17.349814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips, ImageSequenceClip\n",
    "\n",
    "def resize_images(image_paths, target_size, temp_folder=\"temp_images\"):\n",
    "    os.makedirs(temp_folder, exist_ok=True)  # 创建临时文件夹存储调整大小的图片\n",
    "    resized_images = []\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img, target_size)  # 调整图片大小\n",
    "        temp_img_path = os.path.join(temp_folder, f\"temp_{i}.jpg\")\n",
    "        cv2.imwrite(temp_img_path, img_resized)  # 保存调整后的图片\n",
    "        resized_images.append(temp_img_path)\n",
    "    return resized_images\n",
    "\n",
    "def create_video_from_images(image_folder, output_video, fps=2, music_path=None, transition=True):\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "    images.sort()  # 按文件名排序\n",
    "    \n",
    "    if not images:\n",
    "        print(\"No images found in the folder.\")\n",
    "        return\n",
    "    \n",
    "    image_paths = [os.path.join(image_folder, img) for img in images]\n",
    "    \n",
    "    # 获取第一张图片的尺寸作为标准\n",
    "    first_image = cv2.imread(image_paths[0])\n",
    "    target_size = (first_image.shape[1], first_image.shape[0])  # (width, height)\n",
    "    \n",
    "    # 调整所有图片大小\n",
    "    resized_images = resize_images(image_paths, target_size)\n",
    "    \n",
    "    clip = ImageSequenceClip(resized_images, fps=fps)\n",
    "    \n",
    "    if transition:\n",
    "        clip = apply_transition_effects(clip)\n",
    "    \n",
    "    if music_path and os.path.exists(music_path):\n",
    "        audio = AudioFileClip(music_path).set_duration(clip.duration)\n",
    "        clip = clip.set_audio(audio)\n",
    "    \n",
    "    clip.write_videofile(output_video, codec='libx264', fps=fps)\n",
    "\n",
    "def apply_transition_effects(clip):\n",
    "    clips = [ImageSequenceClip([frame], fps=clip.fps).set_duration(0.5) for frame in clip.iter_frames()]\n",
    "    return concatenate_videoclips(clips, method=\"compose\", padding=-0.25)\n",
    "\n",
    "image_folder = \"photos\"  # 照片所在文件夹\n",
    "output_video = \"output.mp4\"  # 输出视频\n",
    "music_path = \"111.mp3\"  # 背景音乐\n",
    "create_video_from_images(image_folder, output_video, fps=1, music_path=music_path, transition=True)\n"
   ],
   "id": "b3f6b85108fca3f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output.mp4.\n",
      "MoviePy - Writing audio in outputTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output.mp4\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T02:48:12.393527Z",
     "start_time": "2025-03-26T02:48:09.172847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips, ImageSequenceClip, ImageClip\n",
    "import moviepy.video.fx as vfx  # 引入 moviepy 的特效模块\n",
    "\n",
    "def resize_images(image_paths, target_size, temp_folder=\"temp_images\"):\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "    resized_images = []\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_resized = cv2.resize(img, target_size)\n",
    "        temp_img_path = os.path.join(temp_folder, f\"temp_{i}.jpg\")\n",
    "        cv2.imwrite(temp_img_path, img_resized)\n",
    "        resized_images.append(temp_img_path)\n",
    "    return resized_images\n",
    "\n",
    "def apply_transition_effects(image_paths, duration=2.0, transition_duration=0.5):\n",
    "    \"\"\" 使用 vfx.fadein 和 vfx.fadeout 添加淡入淡出效果 \"\"\"\n",
    "    clips = []\n",
    "    for img_path in image_paths:\n",
    "        clip = ImageClip(img_path, duration=duration)\n",
    "        clip = vfx.CrossFadeIn(clip)\n",
    "        clip = vfx.CrossFadeOut(clip)\n",
    "        clips.append(clip)\n",
    "    \n",
    "    return concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "def create_video_from_images(image_folder, output_video, fps=2, music_path=None, transition=True):\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "    images.sort()\n",
    "    \n",
    "    if not images:\n",
    "        print(\"No images found in the folder.\")\n",
    "        return\n",
    "    \n",
    "    image_paths = [os.path.join(image_folder, img) for img in images]\n",
    "    \n",
    "    first_image = cv2.imread(image_paths[0])\n",
    "    target_size = (first_image.shape[1], first_image.shape[0])\n",
    "    \n",
    "    resized_images = resize_images(image_paths, target_size)\n",
    "    \n",
    "    if transition:\n",
    "        clip = apply_transition_effects(resized_images, duration=2.0, transition_duration=0.5)\n",
    "    else:\n",
    "        clip = ImageSequenceClip(resized_images, fps=fps)\n",
    "    \n",
    "    if music_path and os.path.exists(music_path):\n",
    "        audio = AudioFileClip(music_path).set_duration(clip.duration)\n",
    "        clip = clip.set_audio(audio)\n",
    "    \n",
    "    clip.write_videofile(output_video, codec='libx264', fps=fps)\n",
    "    \n",
    "    # Cleanup temporary images\n",
    "    for temp_img in resized_images:\n",
    "        os.remove(temp_img)\n",
    "    os.rmdir(\"temp_images\")  # Remove the temporary folder\n",
    "\n",
    "image_folder = \"photos\"\n",
    "output_video = \"output.mp4\"\n",
    "music_path = \"111.mp3\"\n",
    "create_video_from_images(image_folder, output_video, fps=2, music_path=music_path, transition=True)\n"
   ],
   "id": "31094b25fb4daca5",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'CrossFadeIn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 63\u001B[0m\n\u001B[0;32m     61\u001B[0m output_video \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput.mp4\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     62\u001B[0m music_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValentin - Unchanged Mind.mp3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 63\u001B[0m \u001B[43mcreate_video_from_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_video\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmusic_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmusic_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[16], line 45\u001B[0m, in \u001B[0;36mcreate_video_from_images\u001B[1;34m(image_folder, output_video, fps, music_path, transition)\u001B[0m\n\u001B[0;32m     42\u001B[0m resized_images \u001B[38;5;241m=\u001B[39m resize_images(image_paths, target_size)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transition:\n\u001B[1;32m---> 45\u001B[0m     clip \u001B[38;5;241m=\u001B[39m \u001B[43mapply_transition_effects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresized_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mduration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransition_duration\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     47\u001B[0m     clip \u001B[38;5;241m=\u001B[39m ImageSequenceClip(resized_images, fps\u001B[38;5;241m=\u001B[39mfps)\n",
      "Cell \u001B[1;32mIn[16], line 27\u001B[0m, in \u001B[0;36mapply_transition_effects\u001B[1;34m(image_paths, duration, transition_duration)\u001B[0m\n\u001B[0;32m     24\u001B[0m     clip \u001B[38;5;241m=\u001B[39m vfx\u001B[38;5;241m.\u001B[39mCrossFadeOut(clip)\n\u001B[0;32m     25\u001B[0m     clips\u001B[38;5;241m.\u001B[39mappend(clip)\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcatenate_videoclips\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclips\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompose\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\moviepy\\video\\compositing\\CompositeVideoClip.py:322\u001B[0m, in \u001B[0;36mconcatenate_videoclips\u001B[1;34m(clips, method, transition, bg_color, is_mask, padding)\u001B[0m\n\u001B[0;32m    319\u001B[0m     clips \u001B[38;5;241m=\u001B[39m reduce(\u001B[38;5;28;01mlambda\u001B[39;00m x, y: x \u001B[38;5;241m+\u001B[39m y, clip_transition_pairs) \u001B[38;5;241m+\u001B[39m [clips[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]]\n\u001B[0;32m    320\u001B[0m     transition \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 322\u001B[0m timings \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcumsum\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mclip\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mduration\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclip\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclips\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    324\u001B[0m sizes \u001B[38;5;241m=\u001B[39m [clip\u001B[38;5;241m.\u001B[39msize \u001B[38;5;28;01mfor\u001B[39;00m clip \u001B[38;5;129;01min\u001B[39;00m clips]\n\u001B[0;32m    326\u001B[0m w \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(size[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m size \u001B[38;5;129;01min\u001B[39;00m sizes)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2586\u001B[0m, in \u001B[0;36mcumsum\u001B[1;34m(a, axis, dtype, out)\u001B[0m\n\u001B[0;32m   2512\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_cumsum_dispatcher)\n\u001B[0;32m   2513\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcumsum\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   2514\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2515\u001B[0m \u001B[38;5;124;03m    Return the cumulative sum of the elements along a given axis.\u001B[39;00m\n\u001B[0;32m   2516\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2584\u001B[0m \n\u001B[0;32m   2585\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2586\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcumsum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56\u001B[0m, in \u001B[0;36m_wrapfunc\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     54\u001B[0m bound \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, method, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bound \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bound(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:45\u001B[0m, in \u001B[0;36m_wrapit\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m     44\u001B[0m     wrap \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 45\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(asarray(obj), method)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wrap:\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, mu\u001B[38;5;241m.\u001B[39mndarray):\n",
      "\u001B[1;31mTypeError\u001B[0m: unsupported operand type(s) for +: 'int' and 'CrossFadeIn'"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
