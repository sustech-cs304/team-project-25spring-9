{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:26:17.581462Z",
     "start_time": "2025-03-24T05:26:05.295502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import piexif\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Nominatim\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "# PHOTO_DIR = \"photos/\"\n",
    "# SORTED_DIR = \"sorted_photos/\"\n",
    "ENCODINGS_FILE = \"face_encodings.json\"\n",
    "# å…¨å±€å˜é‡\n",
    "processor = None\n",
    "model = None\n",
    "nlp = None\n",
    "\n",
    "# os.makedirs(SORTED_DIR, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# ğŸŒŸ åŠ è½½å·²æœ‰çš„äººè„¸æ•°æ®ï¼ˆJSON æ–‡ä»¶ï¼‰\n",
    "# ==========================\n",
    "def load_encodings():\n",
    "    global next_label_id\n",
    "    if not os.path.exists(ENCODINGS_FILE):\n",
    "        print(\"ğŸ“‚ æ²¡æœ‰æ£€æµ‹åˆ°ç°æœ‰çš„äººè„¸æ•°æ®åº“ï¼Œåˆå§‹åŒ–ä¸ºç©ºã€‚\")\n",
    "        return {}, [], []\n",
    "\n",
    "    with open(ENCODINGS_FILE, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    known_face_dict = {}  # {label: encoding (np array)}\n",
    "    known_face_encodings = []\n",
    "    known_face_labels = []\n",
    "\n",
    "    for label, encoding_list in data.items():\n",
    "        label_int = int(label)\n",
    "        encoding_array = np.array(encoding_list)\n",
    "        known_face_dict[label_int] = encoding_array\n",
    "        known_face_encodings.append(encoding_array)\n",
    "        known_face_labels.append(label_int)\n",
    "    \n",
    "    next_label_id = max(known_face_dict.keys(), default=0) + 1\n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½ {len(known_face_dict)} ä¸ªå·²çŸ¥äººç‰©æ•°æ®ã€‚\")\n",
    "    return known_face_dict, known_face_encodings, known_face_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ğŸŒŸ ä¿å­˜äººè„¸ç¼–ç åˆ° JSON\n",
    "# ==========================\n",
    "def save_encodings(known_face_dict):\n",
    "    data_to_save = {}\n",
    "    for label, encoding_array in known_face_dict.items():\n",
    "        data_to_save[label] = encoding_array.tolist()  # è½¬æˆ JSON å¯ä¿å­˜çš„ list\n",
    "    \n",
    "    with open(ENCODINGS_FILE, 'w') as f:\n",
    "        json.dump(data_to_save, f)\n",
    "    \n",
    "    print(f\"ğŸ’¾ å·²ä¿å­˜ {len(data_to_save)} ä¸ªäººç‰©çš„ç¼–ç æ•°æ®åˆ° {ENCODINGS_FILE}\")\n",
    "    \n",
    "    \n",
    "\n",
    "# åˆå§‹åŒ–å‡½æ•°\n",
    "def init_blip_and_spacy():\n",
    "    global processor, model, nlp  # å¼•ç”¨å…¨å±€å˜é‡\n",
    "    try:\n",
    "        print(\"æ­£åœ¨åŠ è½½ BLIP æ¨¡å‹å’Œå¤„ç†å™¨...\")\n",
    "        processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "        model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "        print(\"BLIP æ¨¡å‹å’Œå¤„ç†å™¨åŠ è½½å®Œæˆï¼\")\n",
    "    except Exception as e:\n",
    "        print(f\"åŠ è½½ BLIP æ¨¡å‹æ—¶å‡ºé”™: {e}\")\n",
    "        processor, model = None, None\n",
    "\n",
    "    try:\n",
    "        print(\"æ­£åœ¨æ£€æµ‹å’ŒåŠ è½½ SpaCy è‹±æ–‡æ¨¡å‹...\")\n",
    "        download(\"en_core_web_sm\")  # åªä¸‹è½½ä¸€æ¬¡\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        print(\"SpaCy è‹±æ–‡æ¨¡å‹åŠ è½½å®Œæˆï¼\")\n",
    "    except Exception as e:\n",
    "        print(f\"åŠ è½½ SpaCy æ¨¡å‹æ—¶å‡ºé”™: {e}\")\n",
    "        nlp = None\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# ğŸŒŸ å¤„ç†å•å¼ å›¾ç‰‡\n",
    "# ==========================\n",
    "def process_new_photo(photo_path):\n",
    "    global next_label_id\n",
    "    try:\n",
    "        # 1. æ‰“å¼€å¹¶è½¬æ¢å›¾ç‰‡\n",
    "        with Image.open(photo_path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "            image_array = np.array(img)\n",
    "        \n",
    "        # 2. äººè„¸è¯†åˆ«\n",
    "        encodings = face_recognition.face_encodings(image_array)\n",
    "\n",
    "        if not encodings:\n",
    "            print(f\"âš ï¸ å›¾ç‰‡ {photo_path} ä¸åŒ…å«äººè„¸ï¼Œè·³è¿‡å¤„ç†ã€‚\")\n",
    "            return\n",
    "        \n",
    "        print(f\"âœ… è¯†åˆ«åˆ° {len(encodings)} å¼ äººè„¸ï¼Œå¼€å§‹åˆ†ç±»...\")\n",
    "\n",
    "        for encoding in encodings:\n",
    "            if len(known_face_encodings) == 0:\n",
    "                # æ²¡æœ‰äººè„¸æ•°æ®ï¼Œç›´æ¥æ–°å»ºäººç‰©\n",
    "                person_label = next_label_id\n",
    "                next_label_id += 1\n",
    "\n",
    "                known_face_dict[person_label] = encoding\n",
    "                known_face_encodings.append(encoding)\n",
    "                known_face_labels.append(person_label)\n",
    "                print(f\"ğŸ†• æœªæ£€æµ‹åˆ°å·²æœ‰äººç‰©ï¼Œæ–°å»ºäººç‰© {person_label}\")\n",
    "\n",
    "            else:\n",
    "                # æ¯”è¾ƒä¸å·²çŸ¥äººè„¸çš„ç›¸ä¼¼åº¦\n",
    "                distances = face_recognition.face_distance(known_face_encodings, encoding)\n",
    "                min_distance = np.min(distances)\n",
    "                best_match_index = np.argmin(distances)\n",
    "\n",
    "                if min_distance < 0.4:  # é˜ˆå€¼å¯ä»¥è°ƒæ•´\n",
    "                    person_label = known_face_labels[best_match_index]\n",
    "                    # print(f\"ğŸ‘Œ åŒ¹é…åˆ°äººç‰© {person_label}ï¼Œè·ç¦»ä¸º {min_distance:.2f}\")\n",
    "                else:\n",
    "                    # æ–°äººç‰©\n",
    "                    person_label = next_label_id\n",
    "                    next_label_id += 1\n",
    "\n",
    "                    known_face_dict[person_label] = encoding\n",
    "                    known_face_encodings.append(encoding)\n",
    "                    known_face_labels.append(person_label)\n",
    "                    # print(f\"ğŸ†• æ–°å»ºäººç‰© {person_label}ï¼Œè·ç¦»ä¸º {min_distance:.2f}\")\n",
    "            \n",
    "            # ä¿å­˜ç…§ç‰‡åˆ°åˆ†ç±»ç›®å½•\n",
    "            person_folder = os.path.join(SORTED_DIR, f\"äººç‰©{person_label}\")\n",
    "            os.makedirs(person_folder, exist_ok=True)\n",
    "            shutil.copy(photo_path, person_folder)\n",
    "        \n",
    "        # å¤„ç†å®Œå›¾ç‰‡ï¼Œä¿å­˜æœ€æ–°çš„ encodings\n",
    "        save_encodings(known_face_dict)\n",
    "        return person_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å¤„ç† {photo_path} æ—¶å‡ºé”™: {e}\")\n",
    "\n",
    "def get_decimal_from_dms(dms, ref):\n",
    "    \"\"\"Convert GPS coordinates in DMS to decimal format.\"\"\"\n",
    "    degrees = dms[0][0] / dms[0][1]\n",
    "    minutes = dms[1][0] / dms[1][1]\n",
    "    seconds = dms[2][0] / dms[2][1]\n",
    "\n",
    "    decimal = degrees + (minutes / 60.0) + (seconds / 3600.0)\n",
    "\n",
    "    if ref in ['S', 'W']:\n",
    "        decimal = -decimal\n",
    "    return decimal\n",
    "\n",
    "def reverse_geocode(lat, lon):\n",
    "    \"\"\"Use geopy to reverse geocode latitude and longitude to address.\"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"photo_metadata_app\")\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), exactly_one=True, language='en')\n",
    "        if location:\n",
    "            return location.address\n",
    "        else:\n",
    "            return \"Address not found\"\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving address: {e}\"\n",
    "\n",
    "def extract_exif_data(image_path):\n",
    "    # æ‰“å¼€å›¾ç‰‡æ–‡ä»¶\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # è·å– EXIF ä¿¡æ¯\n",
    "    exif_data = img._getexif()\n",
    "\n",
    "    # æå–æ‹æ‘„æ—¶é—´\n",
    "    timestamp = None\n",
    "    if exif_data and 36867 in exif_data:\n",
    "        timestamp = exif_data[36867]  # DateTimeOriginal\n",
    "        timestamp = datetime.strptime(timestamp, '%Y:%m:%d %H:%M:%S')\n",
    "\n",
    "    # ä½¿ç”¨ piexif åŠ è½½æ›´è¯¦ç»†çš„ EXIF æ•°æ®\n",
    "    exif_dict = piexif.load(img.info['exif']) if 'exif' in img.info else None\n",
    "\n",
    "    # æå–ç›¸æœº/è®¾å¤‡ä¿¡æ¯\n",
    "    camera_model = None\n",
    "    if exif_dict:\n",
    "        model = exif_dict['0th'].get(piexif.ImageIFD.Model, None)\n",
    "        make = exif_dict['0th'].get(piexif.ImageIFD.Make, None)\n",
    "\n",
    "        camera_model = \"\"\n",
    "        if make:\n",
    "            camera_model += make.decode('utf-8') + \" \"\n",
    "        if model:\n",
    "            camera_model += model.decode('utf-8')\n",
    "\n",
    "    # æå– GPS ä¿¡æ¯\n",
    "    gps_info = exif_dict.get('GPS', None) if exif_dict else None\n",
    "    latitude = longitude = None\n",
    "    address = None\n",
    "    if gps_info:\n",
    "        gps_latitude = gps_info.get(piexif.GPSIFD.GPSLatitude)\n",
    "        gps_latitude_ref = gps_info.get(piexif.GPSIFD.GPSLatitudeRef).decode('utf-8')\n",
    "        gps_longitude = gps_info.get(piexif.GPSIFD.GPSLongitude)\n",
    "        gps_longitude_ref = gps_info.get(piexif.GPSIFD.GPSLongitudeRef).decode('utf-8')\n",
    "\n",
    "        if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n",
    "            latitude = get_decimal_from_dms(gps_latitude, gps_latitude_ref)\n",
    "            longitude = get_decimal_from_dms(gps_longitude, gps_longitude_ref)\n",
    "\n",
    "            # åå‘åœ°ç†ç¼–ç è·å–åœ°å€\n",
    "            address = reverse_geocode(latitude, longitude)\n",
    "\n",
    "    # è¿”å›æå–çš„ä¿¡æ¯\n",
    "    return {\n",
    "        'Timestamp': timestamp,\n",
    "        'Latitude': latitude,\n",
    "        'Longitude': longitude,\n",
    "        'Address': address,\n",
    "        'Camera/Device': camera_model\n",
    "    }\n",
    "\n",
    "# ç”Ÿæˆå›¾ç‰‡æè¿°\n",
    "def generate_caption(image_path):\n",
    "    try:\n",
    "        raw_image = Image.open(image_path).convert('RGB')\n",
    "        inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "        out = model.generate(**inputs)\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        print(f\"Caption generation error for {image_path}: {e}\")\n",
    "        return \"No description available.\"\n",
    "    \n",
    "def extract_noun_tags(text):\n",
    "    \"\"\"\n",
    "    æå–è‹±æ–‡æ–‡æœ¬ä¸­çš„å…³é”®è¯ï¼ˆåè¯å’Œä¸“æœ‰åè¯ï¼‰\n",
    "\n",
    "    å‚æ•°:\n",
    "        text (str): è¾“å…¥çš„è‹±æ–‡æ–‡æœ¬\n",
    "\n",
    "    è¿”å›:\n",
    "        tags (list): å»é‡ä¸”å°å†™å¤„ç†åçš„å…³é”®è¯åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    # åˆ†è¯ & è¯æ€§æ ‡æ³¨\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # åªä¿ç•™åè¯ï¼ˆNOUNï¼‰å’Œä¸“æœ‰åè¯ï¼ˆPROPNï¼‰\n",
    "    tags = [token.text for token in doc if token.pos_ in ['NOUN', 'PROPN']]\n",
    "\n",
    "    # å»é‡ & å°å†™ï¼ˆå¯æ ¹æ®éœ€æ±‚å–æ¶ˆå°å†™å¤„ç†ï¼‰\n",
    "    tags = list(set(tag.lower() for tag in tags))\n",
    "    \n",
    "    print(f\"Image event tags: {tags}\")\n",
    "\n",
    "    return tags\n",
    "\n",
    "\n",
    "# å¤„ç†å›¾ç‰‡\n",
    "def process_images(img_path):\n",
    "    # æå–å…ƒä¿¡æ¯\n",
    "    metadata = extract_exif_data(img_path)\n",
    "    \n",
    "    # ç”Ÿæˆæè¿°\n",
    "    caption = generate_caption(img_path)\n",
    "\n",
    "    #Aoto-tagging\n",
    "    tags = extract_noun_tags(caption)\n",
    "    \n",
    "    #äººè„¸è¯†åˆ« \n",
    "    person_label = process_new_photo(img_path)\n",
    "    \n",
    "    # âœ… å¹³é“º JSON æ ¼å¼\n",
    "    photo_info = {\n",
    "        'Timestamp': metadata.get('Timestamp'),\n",
    "        'Latitude': metadata.get('Latitude'),\n",
    "        'Longitude': metadata.get('Longitude'),\n",
    "        'Address': metadata.get('Address'),\n",
    "        'Camera/Device': metadata.get('Camera/Device'),\n",
    "        'Caption': caption,\n",
    "        'AutoTags': tags,\n",
    "        'PersonLabel': person_label\n",
    "    }\n",
    "    \n",
    "    print(f\"Processed {img_path}: {caption} @ {photo_info.get('Address')} on {photo_info.get('Timestamp')}\") \n",
    "    \n",
    "    return photo_info"
   ],
   "id": "7d4b2e575328b714",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:26:44.173382Z",
     "start_time": "2025-03-24T05:26:21.998007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================\n",
    "# ğŸŒŸ åˆå§‹åŒ–å·²çŸ¥äººè„¸æ•°æ®\n",
    "# ==========================\n",
    "known_face_dict, known_face_encodings, known_face_labels = load_encodings()\n",
    "# è°ƒç”¨åˆå§‹åŒ–å‡½æ•°\n",
    "# è°ƒç”¨åˆå§‹åŒ–ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰\n",
    "init_blip_and_spacy()\n",
    "\n",
    "process_images(\"photos/12.jpg\")"
   ],
   "id": "bdba0f0b5a7914cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸåŠ è½½ 8 ä¸ªå·²çŸ¥äººç‰©æ•°æ®ã€‚\n",
      "æ­£åœ¨åŠ è½½ BLIP æ¨¡å‹å’Œå¤„ç†å™¨...\n",
      "BLIP æ¨¡å‹å’Œå¤„ç†å™¨åŠ è½½å®Œæˆï¼\n",
      "æ­£åœ¨æ£€æµ‹å’ŒåŠ è½½ SpaCy è‹±æ–‡æ¨¡å‹...\n",
      "\u001B[38;5;2mâœ” Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001B[38;5;3mâš  Restart to reload dependencies\u001B[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "SpaCy è‹±æ–‡æ¨¡å‹åŠ è½½å®Œæˆï¼\n",
      "Image event tags: ['table', 'phone', 'boy', 'cell']\n",
      "âœ… è¯†åˆ«åˆ° 1 å¼ äººè„¸ï¼Œå¼€å§‹åˆ†ç±»...\n",
      "âŒ å¤„ç† photos/12.jpg æ—¶å‡ºé”™: name 'SORTED_DIR' is not defined\n",
      "Processed photos/12.jpg: a young boy sitting at a table with a cell phone @ é“¶æ™–è·¯, Haiwang, Xin'an Sub-District, Bao'an District, Shenzhen, Guangdong Province, 518100, China on 2025-01-17 21:05:14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Timestamp': datetime.datetime(2025, 1, 17, 21, 5, 14),\n",
       " 'Latitude': 22.552558333333334,\n",
       " 'Longitude': 113.88952777777779,\n",
       " 'Address': \"é“¶æ™–è·¯, Haiwang, Xin'an Sub-District, Bao'an District, Shenzhen, Guangdong Province, 518100, China\",\n",
       " 'Camera/Device': 'Xiaomi 2203121C',\n",
       " 'Caption': 'a young boy sitting at a table with a cell phone',\n",
       " 'AutoTags': ['table', 'phone', 'boy', 'cell'],\n",
       " 'PersonLabel': None}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.responses import JSONResponse\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    global known_face_dict, known_face_encodings, known_face_labels\n",
    "    known_face_dict, known_face_encodings, known_face_labels = load_encodings()\n",
    "    init_blip_and_spacy()\n",
    "\n",
    "# ä¸Šä¼ å›¾ç‰‡æ¥å£\n",
    "@app.post(\"/process_image\")\n",
    "async def process_image(file: UploadFile = File(...)):\n",
    "    try:        \n",
    "        # è°ƒç”¨å¤„ç†å‡½æ•°\n",
    "        result = process_images(file)\n",
    "\n",
    "        # è¿”å› JSON\n",
    "        return JSONResponse(content=result)\n",
    "\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"error\": str(e)})"
   ],
   "id": "b92e14409d1831f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
