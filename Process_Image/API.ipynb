{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T14:23:24.952137Z",
     "start_time": "2025-05-21T14:22:55.758952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import piexif\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Nominatim\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import torch\n",
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "PHOTO_DIR = \"photos/\"\n",
    "SORTED_DIR = \"sorted_photos/\"\n",
    "ENCODINGS_FILE = \"face_encodings.json\"\n",
    "# 全局变量\n",
    "processor = None\n",
    "model = None\n",
    "nlp = None\n",
    "\n",
    "# os.makedirs(SORTED_DIR, exist_ok=True)\n",
    "\n",
    "# ==========================\n",
    "# 🌟 加载已有的人脸数据（JSON 文件）\n",
    "# ==========================\n",
    "def load_encodings():\n",
    "    global next_label_id\n",
    "    if not os.path.exists(ENCODINGS_FILE):\n",
    "        print(\"📂 没有检测到现有的人脸数据库，初始化为空。\")\n",
    "        return {}, [], []\n",
    "\n",
    "    with open(ENCODINGS_FILE, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    known_face_dict = {}  # {label: encoding (np array)}\n",
    "    known_face_encodings = []\n",
    "    known_face_labels = []\n",
    "\n",
    "    for label, encoding_list in data.items():\n",
    "        label_int = int(label)\n",
    "        encoding_array = np.array(encoding_list)\n",
    "        known_face_dict[label_int] = encoding_array\n",
    "        known_face_encodings.append(encoding_array)\n",
    "        known_face_labels.append(label_int)\n",
    "    \n",
    "    next_label_id = max(known_face_dict.keys(), default=0) + 1\n",
    "    print(f\"✅ 成功加载 {len(known_face_dict)} 个已知人物数据。\")\n",
    "    return known_face_dict, known_face_encodings, known_face_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 🌟 保存人脸编码到 JSON\n",
    "# ==========================\n",
    "def save_encodings(known_face_dict):\n",
    "    data_to_save = {}\n",
    "    for label, encoding_array in known_face_dict.items():\n",
    "        data_to_save[label] = encoding_array.tolist()  # 转成 JSON 可保存的 list\n",
    "    \n",
    "    with open(ENCODINGS_FILE, 'w') as f:\n",
    "        json.dump(data_to_save, f)\n",
    "    \n",
    "    print(f\"💾 已保存 {len(data_to_save)} 个人物的编码数据到 {ENCODINGS_FILE}\")\n",
    "    \n",
    "    \n",
    "\n",
    "# 初始化函数\n",
    "def init_blip_and_spacy():\n",
    "    global processor, model, nlp  # 引用全局变量\n",
    "    try:\n",
    "        print(\"正在加载 BLIP 模型和处理器...\")\n",
    "        processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "        model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "        print(\"BLIP 模型和处理器加载完成！\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载 BLIP 模型时出错: {e}\")\n",
    "        processor, model = None, None\n",
    "\n",
    "    try:\n",
    "        print(\"正在检测和加载 SpaCy 英文模型...\")\n",
    "        download(\"en_core_web_sm\")  # 只下载一次\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        print(\"SpaCy 英文模型加载完成！\")\n",
    "    except Exception as e:\n",
    "        print(f\"加载 SpaCy 模型时出错: {e}\")\n",
    "        nlp = None\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 🌟 处理单张图片\n",
    "# ==========================\n",
    "def process_new_photo(photo_path):\n",
    "    global next_label_id\n",
    "    try:\n",
    "        # 1. 打开并转换图片\n",
    "        with Image.open(photo_path) as img:\n",
    "            img = img.convert(\"RGB\")\n",
    "            image_array = np.array(img)\n",
    "        \n",
    "        # 2. 人脸识别\n",
    "        encodings = face_recognition.face_encodings(image_array,model='large')\n",
    "\n",
    "        if not encodings:\n",
    "            print(f\"⚠️ 图片 {photo_path} 不包含人脸，跳过处理。\")\n",
    "            return\n",
    "        \n",
    "        print(f\"✅ 识别到 {len(encodings)} 张人脸，开始分类...\")\n",
    "\n",
    "        for encoding in encodings:\n",
    "            if len(known_face_encodings) == 0:\n",
    "                # 没有人脸数据，直接新建人物\n",
    "                person_label = next_label_id\n",
    "                next_label_id += 1\n",
    "\n",
    "                known_face_dict[person_label] = encoding\n",
    "                known_face_encodings.append(encoding)\n",
    "                known_face_labels.append(person_label)\n",
    "                print(f\"🆕 未检测到已有人物，新建人物 {person_label}\")\n",
    "\n",
    "            else:\n",
    "                # 比较与已知人脸的相似度\n",
    "                distances = face_recognition.face_distance(known_face_encodings, encoding)\n",
    "                min_distance = np.min(distances)\n",
    "                best_match_index = np.argmin(distances)\n",
    "\n",
    "                if min_distance < 0.4:  # 阈值可以调整\n",
    "                    person_label = known_face_labels[best_match_index]\n",
    "                    # print(f\"👌 匹配到人物 {person_label}，距离为 {min_distance:.2f}\")\n",
    "                else:\n",
    "                    # 新人物\n",
    "                    person_label = next_label_id\n",
    "                    next_label_id += 1\n",
    "\n",
    "                    known_face_dict[person_label] = encoding\n",
    "                    known_face_encodings.append(encoding)\n",
    "                    known_face_labels.append(person_label)\n",
    "                    # print(f\"🆕 新建人物 {person_label}，距离为 {min_distance:.2f}\")\n",
    "            \n",
    "            # 保存照片到分类目录\n",
    "            person_folder = os.path.join(SORTED_DIR, f\"人物{person_label}\")\n",
    "            os.makedirs(person_folder, exist_ok=True)\n",
    "            shutil.copy(photo_path, person_folder)\n",
    "        \n",
    "        # 处理完图片，保存最新的 encodings\n",
    "        save_encodings(known_face_dict)\n",
    "        return person_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 处理 {photo_path} 时出错: {e}\")\n",
    "\n",
    "def get_decimal_from_dms(dms, ref):\n",
    "    \"\"\"Convert GPS coordinates in DMS to decimal format.\"\"\"\n",
    "    degrees = dms[0][0] / dms[0][1]\n",
    "    minutes = dms[1][0] / dms[1][1]\n",
    "    seconds = dms[2][0] / dms[2][1]\n",
    "\n",
    "    decimal = degrees + (minutes / 60.0) + (seconds / 3600.0)\n",
    "\n",
    "    if ref in ['S', 'W']:\n",
    "        decimal = -decimal\n",
    "    return decimal\n",
    "\n",
    "def reverse_geocode(lat, lon):\n",
    "    \"\"\"Use geopy to reverse geocode latitude and longitude to address.\"\"\"\n",
    "    geolocator = Nominatim(user_agent=\"photo_metadata_app\")\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), exactly_one=True, language='en')\n",
    "        if location:\n",
    "            return location.address\n",
    "        else:\n",
    "            return \"Address not found\"\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving address: {e}\"\n",
    "\n",
    "def extract_exif_data(image_path):\n",
    "    # 打开图片文件\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # 获取 EXIF 信息\n",
    "    exif_data = img._getexif()\n",
    "\n",
    "    # 提取拍摄时间\n",
    "    timestamp = None\n",
    "    if exif_data and 36867 in exif_data:\n",
    "        timestamp = exif_data[36867]  # DateTimeOriginal\n",
    "        timestamp = datetime.strptime(timestamp, '%Y:%m:%d %H:%M:%S')\n",
    "\n",
    "    # 使用 piexif 加载更详细的 EXIF 数据\n",
    "    exif_dict = piexif.load(img.info['exif']) if 'exif' in img.info else None\n",
    "\n",
    "    # 提取相机/设备信息\n",
    "    camera_model = None\n",
    "    if exif_dict:\n",
    "        model = exif_dict['0th'].get(piexif.ImageIFD.Model, None)\n",
    "        make = exif_dict['0th'].get(piexif.ImageIFD.Make, None)\n",
    "\n",
    "        camera_model = \"\"\n",
    "        if make:\n",
    "            camera_model += make.decode('utf-8') + \" \"\n",
    "        if model:\n",
    "            camera_model += model.decode('utf-8')\n",
    "\n",
    "    # 提取 GPS 信息\n",
    "    gps_info = exif_dict.get('GPS', None) if exif_dict else None\n",
    "    latitude = longitude = None\n",
    "    address = None\n",
    "    if gps_info:\n",
    "        gps_latitude = gps_info.get(piexif.GPSIFD.GPSLatitude)\n",
    "        gps_latitude_ref = gps_info.get(piexif.GPSIFD.GPSLatitudeRef).decode('utf-8')\n",
    "        gps_longitude = gps_info.get(piexif.GPSIFD.GPSLongitude)\n",
    "        gps_longitude_ref = gps_info.get(piexif.GPSIFD.GPSLongitudeRef).decode('utf-8')\n",
    "\n",
    "        if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n",
    "            latitude = get_decimal_from_dms(gps_latitude, gps_latitude_ref)\n",
    "            longitude = get_decimal_from_dms(gps_longitude, gps_longitude_ref)\n",
    "\n",
    "            # 反向地理编码获取地址\n",
    "            address = reverse_geocode(latitude, longitude)\n",
    "\n",
    "    # 返回提取的信息\n",
    "    return {\n",
    "        'Timestamp': timestamp,\n",
    "        'Latitude': latitude,\n",
    "        'Longitude': longitude,\n",
    "        'Address': address,\n",
    "        'Camera/Device': camera_model\n",
    "    }\n",
    "\n",
    "# 生成图片描述\n",
    "def generate_caption(image_path):\n",
    "    try:\n",
    "        raw_image = Image.open(image_path).convert('RGB')\n",
    "        inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "        out = model.generate(**inputs)\n",
    "        caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "    except Exception as e:\n",
    "        print(f\"Caption generation error for {image_path}: {e}\")\n",
    "        return \"No description available.\"\n",
    "    \n",
    "def extract_noun_tags(text):\n",
    "    \"\"\"\n",
    "    提取英文文本中的关键词（名词和专有名词）\n",
    "\n",
    "    参数:\n",
    "        text (str): 输入的英文文本\n",
    "\n",
    "    返回:\n",
    "        tags (list): 去重且小写处理后的关键词列表\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    # 分词 & 词性标注\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # 只保留名词（NOUN）和专有名词（PROPN）\n",
    "    tags = [token.text for token in doc if token.pos_ in ['NOUN', 'PROPN']]\n",
    "\n",
    "    # 去重 & 小写（可根据需求取消小写处理）\n",
    "    tags = list(set(tag.lower() for tag in tags))\n",
    "    \n",
    "    print(f\"Image event tags: {tags}\")\n",
    "\n",
    "    return tags\n",
    "\n",
    "\n",
    "# 处理图片\n",
    "def process_images(img_path):\n",
    "    # 提取元信息\n",
    "    metadata = extract_exif_data(img_path)\n",
    "    \n",
    "    # 生成描述\n",
    "    caption = generate_caption(img_path)\n",
    "\n",
    "    #Aoto-tagging\n",
    "    tags = extract_noun_tags(caption)\n",
    "    \n",
    "    #人脸识别 \n",
    "    person_label = process_new_photo(img_path)\n",
    "    \n",
    "    # ✅ 平铺 JSON 格式\n",
    "    photo_info = {\n",
    "        'Timestamp': metadata.get('Timestamp'),\n",
    "        'Latitude': metadata.get('Latitude'),\n",
    "        'Longitude': metadata.get('Longitude'),\n",
    "        'Address': metadata.get('Address'),\n",
    "        'Camera/Device': metadata.get('Camera/Device'),\n",
    "        'Caption': caption,\n",
    "        'AutoTags': tags,\n",
    "        'PersonLabel': person_label\n",
    "    }\n",
    "    \n",
    "    print(f\"Processed {img_path}: {caption} @ {photo_info.get('Address')} on {photo_info.get('Timestamp')}\") \n",
    "    \n",
    "    return photo_info"
   ],
   "id": "7d4b2e575328b714",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:30:21.643180Z",
     "start_time": "2025-04-14T03:30:14.595222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==========================\n",
    "# 🌟 初始化已知人脸数据\n",
    "# ==========================\n",
    "known_face_dict, known_face_encodings, known_face_labels = load_encodings()\n",
    "# 调用初始化函数\n",
    "# 调用初始化（只执行一次）\n",
    "init_blip_and_spacy()\n"
   ],
   "id": "4516cb627c34f649",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功加载 11 个已知人物数据。\n",
      "正在加载 BLIP 模型和处理器...\n",
      "BLIP 模型和处理器加载完成！\n",
      "正在检测和加载 SpaCy 英文模型...\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001B[38;5;3m⚠ Restart to reload dependencies\u001B[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "SpaCy 英文模型加载完成！\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:30:32.475287Z",
     "start_time": "2025-04-14T03:30:24.153772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "process_images(\"photos/15.jpg\")"
   ],
   "id": "bdba0f0b5a7914cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image event tags: ['man', 'fountain', 'front']\n",
      "✅ 识别到 7 张人脸，开始分类...\n",
      "💾 已保存 11 个人物的编码数据到 face_encodings.json\n",
      "Processed photos/15.jpg: a man standing in front of a fountain @ Window of the World, Shennan Boulevard, Huaxia Jie, Shahe Sub-district, Nanshan District, Shenzhen, Guangdong Province, 518000, China on 2025-01-31 18:03:58\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Timestamp': datetime.datetime(2025, 1, 31, 18, 3, 58),\n",
       " 'Latitude': 22.536686111111113,\n",
       " 'Longitude': 113.97063611111112,\n",
       " 'Address': 'Window of the World, Shennan Boulevard, Huaxia Jie, Shahe Sub-district, Nanshan District, Shenzhen, Guangdong Province, 518000, China',\n",
       " 'Camera/Device': 'vivo iQOO Neo8 Pro',\n",
       " 'Caption': 'a man standing in front of a fountain',\n",
       " 'AutoTags': ['man', 'fountain', 'front'],\n",
       " 'PersonLabel': 6}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.responses import JSONResponse\n",
    "import shutil\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup_event():\n",
    "    global known_face_dict, known_face_encodings, known_face_labels\n",
    "    known_face_dict, known_face_encodings, known_face_labels = load_encodings()\n",
    "    init_blip_and_spacy()\n",
    "\n",
    "# 上传图片接口\n",
    "@app.post(\"/process_image\")\n",
    "async def process_image(file: UploadFile = File(...)):\n",
    "    try:        \n",
    "        # 调用处理函数\n",
    "        result = process_images(file)\n",
    "\n",
    "        # 返回 JSON\n",
    "        return JSONResponse(content=result)\n",
    "\n",
    "    except Exception as e:\n",
    "        return JSONResponse(status_code=500, content={\"error\": str(e)})"
   ],
   "id": "b92e14409d1831f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T06:47:37.939061Z",
     "start_time": "2025-04-07T06:47:26.342179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:8123/process_image\"\n",
    "files = {'file': open('photos/13.jpg', 'rb')}\n",
    "response = requests.post(url, files=files)\n",
    "print(response.json())"
   ],
   "id": "be7e7d2cc4af0e19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Timestamp': '2025-02-28 21:14:13', 'Latitude': 22.585355, 'Longitude': 113.950085, 'Address': '沙河西路辅路, 九祥岭, Xili Sub-District, Nanshan District, Guangdong Province, 518000, China', 'Camera/Device': 'Xiaomi 23013RK75C', 'Caption': 'a boy is cooking a meal in a pan', 'AutoTags': ['meal', 'pan', 'boy'], 'PersonLabel': None}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T13:03:15.887620Z",
     "start_time": "2025-05-21T13:03:12.035245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# video_generator.py\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import json\n",
    "import chardet\n",
    "from PIL import Image, ImageFilter\n",
    "from moviepy.editor import (\n",
    "    ImageSequenceClip, AudioFileClip, CompositeVideoClip,\n",
    "    concatenate_videoclips, VideoFileClip, vfx\n",
    ")\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "def get_config():\n",
    "    config_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'config.json')\n",
    "    with open(config_file, 'rb') as f:\n",
    "        encoding_result = chardet.detect(raw_data := f.read())\n",
    "        encoding = encoding_result['encoding']\n",
    "    return json.loads(raw_data.decode(encoding))\n",
    "\n",
    "def transform_image(img, t, x_speed, y_speed, move_on_x, move_positive):\n",
    "    original_size = img.size\n",
    "    crop_width = img.width * 0.8\n",
    "    crop_height = img.height * 0.8\n",
    "    if move_on_x:\n",
    "        left = min(x_speed * t, img.width - crop_width) if move_positive else max(img.width - crop_width - x_speed * t, 0)\n",
    "        upper = (img.height - crop_height) / 2\n",
    "    else:\n",
    "        upper = min(y_speed * t, img.height - crop_height) if move_positive else max(img.height - crop_height - y_speed * t, 0)\n",
    "        left = (img.width - crop_width) / 2\n",
    "    cropped_img = img.crop((left, upper, left + crop_width, upper + crop_height))\n",
    "    return cropped_img.resize(original_size)\n",
    "\n",
    "def generate_video(image_paths: list[str]) -> str:\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    config = get_config()\n",
    "\n",
    "    temp_dir = os.path.join(current_dir, 'temp')\n",
    "    video_dir = os.path.join(current_dir, 'video')\n",
    "    voice_path = os.path.join(current_dir, 'bgm', 'bgm.mp3')\n",
    "\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "    fps = config['fps']\n",
    "    enlarge_background = config['enlarge_background']\n",
    "    duration = config['duration']\n",
    "\n",
    "    bgm_audio = AudioFileClip(voice_path)\n",
    "    clips = []\n",
    "\n",
    "    for idx, img_path in enumerate(image_paths):\n",
    "        im = Image.open(img_path)\n",
    "        effect_type = random.choice([0, 1])\n",
    "        if effect_type == 0:\n",
    "            x_speed = (im.width - im.width * 0.8) / duration\n",
    "            y_speed = 0\n",
    "            move_on_x = True\n",
    "            move_positive = random.choice([True, False])\n",
    "        else:\n",
    "            x_speed = 0\n",
    "            y_speed = (im.height - im.height * 0.8) / duration\n",
    "            move_on_x = False\n",
    "            move_positive = random.choice([True, False])\n",
    "\n",
    "        n_frames = int(fps * duration)\n",
    "        frames_foreground = [np.array(transform_image(im, t / fps, x_speed, y_speed, move_on_x, move_positive)) for t in range(n_frames)]\n",
    "        img_foreground = ImageSequenceClip(frames_foreground, fps=fps)\n",
    "\n",
    "        img_blur = im.filter(ImageFilter.GaussianBlur(radius=30))\n",
    "        if enlarge_background:\n",
    "            img_blur = img_blur.resize((int(im.width * 1.1), int(im.height * 1.1)), Image.Resampling.LANCZOS)\n",
    "        frames_background = [np.array(img_blur)] * n_frames\n",
    "        img_background = ImageSequenceClip(frames_background, fps=fps)\n",
    "\n",
    "        final_clip = CompositeVideoClip(\n",
    "            [img_background.set_position(\"center\"), img_foreground.set_position(\"center\")],\n",
    "            size=img_blur.size\n",
    "        )\n",
    "\n",
    "        final_clip = final_clip.set_duration(duration)\n",
    "        temp_clip_path = os.path.join(temp_dir, f'temp_{idx}.mp4')\n",
    "        final_clip.write_videofile(temp_clip_path, logger=None)\n",
    "        clips.append(VideoFileClip(temp_clip_path))\n",
    "        gc.collect()\n",
    "\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "    final_video = final_video.set_audio(bgm_audio.subclip(0, final_video.duration))\n",
    "    output_path = os.path.join(video_dir, f'output_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}.mp4')\n",
    "    final_video.write_videofile(output_path, logger=None)\n",
    "    return output_path\n"
   ],
   "id": "7d5b96f5291c30bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T14:40:38.544973Z",
     "start_time": "2025-05-13T14:40:38.351610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uvicorn\n",
    "# app.py\n",
    "import os\n",
    "import shutil\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.responses import FileResponse\n",
    "from typing import List\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# UPLOAD_FOLDER = os.path.join(os.path.dirname(__file__), \"image\")\n",
    "UPLOAD_FOLDER = os.path.join(os.getcwd(), \"image\")\n",
    "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "\n",
    "@app.post(\"/generate_video/\")\n",
    "async def generate_video_api(files: List[UploadFile] = File(...)):\n",
    "    saved_files = []\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(UPLOAD_FOLDER, file.filename)\n",
    "        with open(file_path, \"wb\") as f:        \n",
    "            content = await file.read()\n",
    "            f.write(content)\n",
    "        saved_files.append(file_path)\n",
    "\n",
    "    try:\n",
    "        output_video_path = generate_video(saved_files)\n",
    "        return FileResponse(output_video_path, media_type=\"video/mp4\", filename=os.path.basename(output_video_path))\n",
    "    finally:\n",
    "        # 清理临时文件\n",
    "        for path in saved_files:\n",
    "            os.remove(path)\n",
    "            \n",
    "    "
   ],
   "id": "8edd1bd56cc1a8cc",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 35\u001B[0m\n\u001B[0;32m     31\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m saved_files:\n\u001B[0;32m     32\u001B[0m             os\u001B[38;5;241m.\u001B[39mremove(path)\n\u001B[1;32m---> 35\u001B[0m \u001B[43muvicorn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mapp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhost\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m0.0.0.0\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mport\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8124\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uvicorn\\main.py:579\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001B[0m\n\u001B[0;32m    577\u001B[0m         Multiprocess(config, target\u001B[38;5;241m=\u001B[39mserver\u001B[38;5;241m.\u001B[39mrun, sockets\u001B[38;5;241m=\u001B[39m[sock])\u001B[38;5;241m.\u001B[39mrun()\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 579\u001B[0m         \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    580\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[0;32m    581\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m  \u001B[38;5;66;03m# pragma: full coverage\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\uvicorn\\server.py:66\u001B[0m, in \u001B[0;36mServer.run\u001B[1;34m(self, sockets)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrun\u001B[39m(\u001B[38;5;28mself\u001B[39m, sockets: \u001B[38;5;28mlist\u001B[39m[socket\u001B[38;5;241m.\u001B[39msocket] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39msetup_event_loop()\n\u001B[1;32m---> 66\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserve\u001B[49m\u001B[43m(\u001B[49m\u001B[43msockets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msockets\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\runners.py:33\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(main, debug)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03mThis function runs the passed coroutine, taking care of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m    asyncio.run(main())\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m events\u001B[38;5;241m.\u001B[39m_get_running_loop() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 33\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masyncio.run() cannot be called from a running event loop\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m coroutines\u001B[38;5;241m.\u001B[39miscoroutine(main):\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma coroutine was expected, got \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(main))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T14:48:40.784738Z",
     "start_time": "2025-05-21T14:48:20.083562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "# 接口地址（请根据需要替换 host 和 port）\n",
    "url = \"http://localhost:8123/generate_video/\"\n",
    "\n",
    "# 要上传的图片文件路径（替换成你自己的）\n",
    "image_paths = [\n",
    "    \"image/output_1.png\",\n",
    "    \"image/output_2.png\",\n",
    "    \"image/output_3.png\",\n",
    "    \"image/output_4.png\",\n",
    "    \"image/output_5.png\",\n",
    "    \"image/output_6.png\",\n",
    "    \"img/IMG_20230909_010443.png\", \n",
    "    \"img/IMG_20230909_030556.png\"\n",
    "]\n",
    "\n",
    "# image_paths = [\"img/IMG_20230909_010443.png\", \"img/IMG_20230909_030556.png\"]\n",
    "\n",
    "# 构建文件列表，格式为元组列表\n",
    "files = [('files', (os.path.basename(path), open(path, 'rb'), 'image/jpeg')) for path in image_paths]\n",
    "\n",
    "# 发送 POST 请求\n",
    "response = requests.post(url, files=files)\n",
    "\n",
    "# 处理响应\n",
    "if response.status_code == 200:\n",
    "    output_path = \"result_video.mp4\"\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"✅ 视频保存成功：{output_path}\")\n",
    "else:\n",
    "    print(f\"❌ 请求失败，状态码: {response.status_code}\")\n",
    "    print(response.text)\n",
    "    \n"
   ],
   "id": "21735846d4ab330c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 视频保存成功：result_video.mp4\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T14:31:50.115228Z",
     "start_time": "2025-05-21T14:31:50.066853Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a4db1261bd298ed3",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Software Engineering\\\\team-project-25spring-9\\\\Process_Image\\\\files'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfiles\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\Image.py:3431\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3428\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mrealpath(os\u001B[38;5;241m.\u001B[39mfspath(fp))\n\u001B[0;32m   3430\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3431\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3432\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3433\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:\\\\Software Engineering\\\\team-project-25spring-9\\\\Process_Image\\\\files'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T15:10:46.448609Z",
     "start_time": "2025-05-13T15:10:43.699597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "# url = \"http://localhost:8123/generate_capetion/\"\n",
    "# url = \"http://localhost:8123/auto_tag/\"\n",
    "# url = \"http://localhost:8123/extract_exif/\"\n",
    "# url = \"http://localhost:8123/face_recognition/\"\n",
    "url = \"http://localhost:8123/process_image/\"\n",
    "files = {'file': open('image/output_2.png', 'rb')}\n",
    "response = requests.post(url, files=files)\n",
    "print(response.json())"
   ],
   "id": "4d37e3fcd0768861",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person_label': 13}\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
